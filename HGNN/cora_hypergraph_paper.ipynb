{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def Eu_dis(x):\n",
    "    \"\"\"\n",
    "    Calculate the distance among each raw of x\n",
    "    :param x: N X D\n",
    "                N: the object number\n",
    "                D: Dimension of the feature\n",
    "    :return: N X N distance matrix\n",
    "    \"\"\"\n",
    "    x = np.mat(x)\n",
    "    aa = np.sum(np.multiply(x, x), 1)\n",
    "    ab = x * x.T\n",
    "    dist_mat = aa + aa.T - 2 * ab\n",
    "    dist_mat[dist_mat < 0] = 0\n",
    "    dist_mat = np.sqrt(dist_mat)\n",
    "    dist_mat = np.maximum(dist_mat, dist_mat.T)\n",
    "    return dist_mat\n",
    "\n",
    "\n",
    "def feature_concat(*F_list, normal_col=False):\n",
    "    \"\"\"\n",
    "    Concatenate multiple modality feature. If the dimension of a feature matrix is more than two,\n",
    "    the function will reduce it into two dimension(using the last dimension as the feature dimension,\n",
    "    the other dimension will be fused as the object dimension)\n",
    "    :param F_list: Feature matrix list\n",
    "    :param normal_col: normalize each column of the feature\n",
    "    :return: Fused feature matrix\n",
    "    \"\"\"\n",
    "    features = None\n",
    "    for f in F_list:\n",
    "        if f is not None and f != []:\n",
    "            # deal with the dimension that more than two\n",
    "            if len(f.shape) > 2:\n",
    "                f = f.reshape(-1, f.shape[-1])\n",
    "            # normal each column\n",
    "            if normal_col:\n",
    "                f_max = np.max(np.abs(f), axis=0)\n",
    "                f = f / f_max\n",
    "            # facing the first feature matrix appended to fused feature matrix\n",
    "            if features is None:\n",
    "                features = f\n",
    "            else:\n",
    "                features = np.hstack((features, f))\n",
    "    if normal_col:\n",
    "        features_max = np.max(np.abs(features), axis=0)\n",
    "        features = features / features_max\n",
    "    return features\n",
    "\n",
    "\n",
    "def hyperedge_concat(*H_list):\n",
    "    \"\"\"\n",
    "    Concatenate hyperedge group in H_list\n",
    "    :param H_list: Hyperedge groups which contain two or more hypergraph incidence matrix\n",
    "    :return: Fused hypergraph incidence matrix\n",
    "    \"\"\"\n",
    "    H = None\n",
    "    for h in H_list:\n",
    "        if h is not None and h != []:\n",
    "            # for the first H appended to fused hypergraph incidence matrix\n",
    "            if H is None:\n",
    "                H = h\n",
    "            else:\n",
    "                if type(h) != list:\n",
    "                    H = np.hstack((H, h))\n",
    "                else:\n",
    "                    tmp = []\n",
    "                    for a, b in zip(H, h):\n",
    "                        tmp.append(np.hstack((a, b)))\n",
    "                    H = tmp\n",
    "    return H\n",
    "\n",
    "\n",
    "def generate_G_from_H(H, variable_weight=False):\n",
    "    \"\"\"\n",
    "    calculate G from hypgraph incidence matrix H\n",
    "    :param H: hypergraph incidence matrix H\n",
    "    :param variable_weight: whether the weight of hyperedge is variable\n",
    "    :return: G\n",
    "    \"\"\"\n",
    "    if type(H) != list:\n",
    "        return _generate_G_from_H(H, variable_weight)\n",
    "    else:\n",
    "        G = []\n",
    "        for sub_H in H:\n",
    "            G.append(generate_G_from_H(sub_H, variable_weight))\n",
    "        return G\n",
    "\n",
    "\n",
    "def _generate_G_from_H(H, variable_weight=False):\n",
    "    \"\"\"\n",
    "    calculate G from hypgraph incidence matrix H\n",
    "    :param H: hypergraph incidence matrix H\n",
    "    :param variable_weight: whether the weight of hyperedge is variable\n",
    "    :return: G\n",
    "    \"\"\"\n",
    "    H = np.array(H)\n",
    "    n_edge = H.shape[1]\n",
    "    # the weight of the hyperedge\n",
    "    W = np.ones(n_edge)\n",
    "    # the degree of the node\n",
    "    DV = np.sum(H * W, axis=1)\n",
    "    # the degree of the hyperedge\n",
    "    DE = np.sum(H, axis=0)\n",
    "    \n",
    "    invDE = np.asmatrix(np.diag(np.power(DE, -1)))\n",
    "    DV2 = np.asmatrix(np.diag(np.power(DV, -0.5)))\n",
    "    W = np.asmatrix(np.diag(W))\n",
    "    H = np.asmatrix(H)\n",
    "    HT = H.T\n",
    "\n",
    "    if variable_weight:\n",
    "        DV2_H = DV2 * H\n",
    "        invDE_HT_DV2 = invDE * HT * DV2\n",
    "        return DV2_H, W, invDE_HT_DV2\n",
    "    else:\n",
    "        G = DV2 * H * W * invDE * HT * DV2\n",
    "        return G\n",
    "\n",
    "\n",
    "def construct_H_with_KNN_from_distance(dis_mat, k_neig, is_probH=True, m_prob=1):\n",
    "    \"\"\"\n",
    "    construct hypregraph incidence matrix from hypergraph node distance matrix\n",
    "    :param dis_mat: node distance matrix\n",
    "    :param k_neig: K nearest neighbor\n",
    "    :param is_probH: prob Vertex-Edge matrix or binary\n",
    "    :param m_prob: prob\n",
    "    :return: N_object X N_hyperedge\n",
    "    \"\"\"\n",
    "    n_obj = dis_mat.shape[0]\n",
    "    # construct hyperedge from the central feature space of each node\n",
    "    n_edge = n_obj\n",
    "    H = np.zeros((n_obj, n_edge))\n",
    "    for center_idx in range(n_obj):\n",
    "        dis_mat[center_idx, center_idx] = 0\n",
    "        dis_vec = dis_mat[center_idx]\n",
    "        nearest_idx = np.array(np.argsort(dis_vec)).squeeze()\n",
    "        avg_dis = np.average(dis_vec)\n",
    "        if not np.any(nearest_idx[:k_neig] == center_idx):\n",
    "            nearest_idx[k_neig - 1] = center_idx\n",
    "\n",
    "        for node_idx in nearest_idx[:k_neig]:\n",
    "            if is_probH:\n",
    "                H[node_idx, center_idx] = np.exp(-dis_vec[0, node_idx] ** 2 / (m_prob * avg_dis) ** 2)\n",
    "            else:\n",
    "                H[node_idx, center_idx] = 1.0\n",
    "    return H\n",
    "\n",
    "\n",
    "def construct_H_with_KNN(X, K_neigs=[10], split_diff_scale=False, is_probH=True, m_prob=1):\n",
    "    \"\"\"\n",
    "    init multi-scale hypergraph Vertex-Edge matrix from original node feature matrix\n",
    "    :param X: N_object x feature_number\n",
    "    :param K_neigs: the number of neighbor expansion\n",
    "    :param split_diff_scale: whether split hyperedge group at different neighbor scale\n",
    "    :param is_probH: prob Vertex-Edge matrix or binary\n",
    "    :param m_prob: prob\n",
    "    :return: N_object x N_hyperedge\n",
    "    \"\"\"\n",
    "    if len(X.shape) != 2:\n",
    "        X = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "    if type(K_neigs) == int:\n",
    "        K_neigs = [K_neigs]\n",
    "\n",
    "    dis_mat = Eu_dis(X)\n",
    "    H = []\n",
    "    for k_neig in K_neigs:\n",
    "        H_tmp = construct_H_with_KNN_from_distance(dis_mat, k_neig, is_probH, m_prob)\n",
    "        if not split_diff_scale:\n",
    "            H = hyperedge_concat(H, H_tmp)\n",
    "        else:\n",
    "            H.append(H_tmp)\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class HGNN_conv(nn.Module):\n",
    "    def __init__(self, in_ft, out_ft, bias=True, device='cuda'):\n",
    "        super(HGNN_conv, self).__init__()\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_ft, out_ft).to(device))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_ft).to(device=device))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, G: torch.Tensor):\n",
    "        # print(type(x))\n",
    "        x = x.matmul(self.weight)\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias\n",
    "        # G = np.array(G)\n",
    "        x = G.matmul(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HGNN_fc(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(HGNN_fc, self).__init__()\n",
    "        self.fc = nn.Linear(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class HGNN_embedding(nn.Module):\n",
    "    def __init__(self, in_ch, n_hid, dropout=0.5):\n",
    "        super(HGNN_embedding, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.hgc1 = HGNN_conv(in_ch, n_hid)\n",
    "        self.hgc2 = HGNN_conv(n_hid, n_hid)\n",
    "\n",
    "    def forward(self, x, G):\n",
    "        x = F.relu(self.hgc1(x, G))\n",
    "        x = F.dropout(x, self.dropout)\n",
    "        x = F.relu(self.hgc2(x, G))\n",
    "        return x\n",
    "\n",
    "\n",
    "class HGNN_classifier(nn.Module):\n",
    "    def __init__(self, n_hid, n_class):\n",
    "        super(HGNN_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_hid, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "from torch import nn\n",
    "# from models import HGNN_conv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, in_ch, n_class, n_hid, dropout=0.5):\n",
    "        super(HGNN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.hgc1 = HGNN_conv(in_ch, n_hid)\n",
    "        self.hgc2 = HGNN_conv(n_hid, n_class)\n",
    "\n",
    "    def forward(self, x, G):\n",
    "        x = F.relu(self.hgc1(x, G))\n",
    "        x = F.dropout(x, self.dropout)\n",
    "        x = self.hgc2(x, G)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18250/1549550332.py:11: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  features = pickle.load(f)  # shape [N, F]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Adjust these paths if needed\n",
    "data_dir = '/home/ridham.patel/hypergraph-baselines-2/HGNN/data/cora/'\n",
    "\n",
    "with open(data_dir + 'features.pickle', 'rb') as f:\n",
    "    features = pickle.load(f)  # shape [N, F]\n",
    "\n",
    "with open(data_dir + 'labels.pickle', 'rb') as f:\n",
    "    labels = pickle.load(f)  # shape [N]\n",
    "\n",
    "with open(data_dir + 'hypergraph.pickle', 'rb') as f:\n",
    "    hypergraph = pickle.load(f)  # dict: author -> [papers]\n",
    "\n",
    "num_nodes = features.shape[0]\n",
    "hyperedges = list(hypergraph.values())\n",
    "\n",
    "# Build incidence matrix H (N x M)\n",
    "rows, cols = [], []\n",
    "for j, edge in enumerate(hyperedges):\n",
    "    for i in edge:\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "\n",
    "H = torch.zeros((num_nodes, len(hyperedges)))\n",
    "H[rows, cols] = 1\n",
    "\n",
    "# return torch.tensor(features.toarray(), dtype=torch.float), torch.tensor(labels), H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(os.path.join(data_dir, 'splits/3.pickle'), 'rb') as f:\n",
    "    split = pickle.load(f)\n",
    "\n",
    "train_idx = torch.LongTensor(split['train'])\n",
    "# test_idx = torch.LongTensor(split['test'])\n",
    "val_idx_np, test_idx_np = train_test_split(split['test'], test_size=0.5, random_state=42, shuffle=True)\n",
    "val_idx = torch.LongTensor(val_idx_np)\n",
    "test_idx = torch.LongTensor(test_idx_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes, feat_dim = features.shape\n",
    "labels = np.array(labels)\n",
    "num_classes = labels.max().item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1072])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGNN(in_ch=feat_dim, n_class=num_classes, n_hid=64, dropout=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 6, ..., 0, 4, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18250/1561467561.py:98: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  H = np.array(H)\n",
      "/tmp/ipykernel_18250/1561467561.py:108: RuntimeWarning: divide by zero encountered in power\n",
      "  DV2 = np.asmatrix(np.diag(np.power(DV, -0.5)))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "features = torch.tensor(features.toarray(), dtype=torch.float)\n",
    "labels = torch.LongTensor(labels)\n",
    "X = features.to(device)\n",
    "# H = H.T\n",
    "y = labels.to(device)\n",
    "train_idx = train_idx.to(device)\n",
    "val_idx = val_idx.to(device)\n",
    "test_idx = test_idx.to(device)\n",
    "G = generate_G_from_H(H)\n",
    "H = H.to(device)\n",
    "G = torch.Tensor(G).to(device)\n",
    "G = torch.nan_to_num(G,nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 1.9845 | Train Acc: 0.1643 | Val Acc: 0.1410\n",
      "Epoch 010 | Loss: 1.7004 | Train Acc: 0.5786 | Val Acc: 0.3879\n",
      "Epoch 020 | Loss: 1.4130 | Train Acc: 0.7643 | Val Acc: 0.5179\n",
      "Epoch 030 | Loss: 1.1649 | Train Acc: 0.8214 | Val Acc: 0.5545\n",
      "Epoch 040 | Loss: 0.9180 | Train Acc: 0.8143 | Val Acc: 0.5693\n",
      "Epoch 050 | Loss: 0.7450 | Train Acc: 0.8357 | Val Acc: 0.5942\n",
      "Epoch 060 | Loss: 0.6210 | Train Acc: 0.8286 | Val Acc: 0.6347\n",
      "Epoch 070 | Loss: 0.5454 | Train Acc: 0.8357 | Val Acc: 0.6464\n",
      "Epoch 080 | Loss: 0.5037 | Train Acc: 0.8357 | Val Acc: 0.6308\n",
      "Epoch 090 | Loss: 0.4685 | Train Acc: 0.8429 | Val Acc: 0.6417\n",
      "Epoch 100 | Loss: 0.4403 | Train Acc: 0.8357 | Val Acc: 0.6371\n",
      "Epoch 110 | Loss: 0.4272 | Train Acc: 0.8429 | Val Acc: 0.6495\n",
      "Epoch 120 | Loss: 0.4109 | Train Acc: 0.8500 | Val Acc: 0.6363\n",
      "Epoch 130 | Loss: 0.4045 | Train Acc: 0.8429 | Val Acc: 0.6449\n",
      "Epoch 140 | Loss: 0.3989 | Train Acc: 0.8429 | Val Acc: 0.6425\n",
      "Epoch 150 | Loss: 0.3931 | Train Acc: 0.8429 | Val Acc: 0.6488\n",
      "Epoch 160 | Loss: 0.3908 | Train Acc: 0.8500 | Val Acc: 0.6355\n",
      "Epoch 170 | Loss: 0.3871 | Train Acc: 0.8500 | Val Acc: 0.6597\n",
      "Epoch 180 | Loss: 0.3811 | Train Acc: 0.8429 | Val Acc: 0.6503\n",
      "Epoch 190 | Loss: 0.3831 | Train Acc: 0.8500 | Val Acc: 0.6472\n",
      "Epoch 200 | Loss: 0.3755 | Train Acc: 0.8500 | Val Acc: 0.6379\n",
      "Test Accuracy: 0.6402\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Training Loop\n",
    "# ---------------------\n",
    "def evaluate(model, X, G, y, indices):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X, G)\n",
    "        preds = logits[indices].argmax(dim=1)\n",
    "        acc = (preds == y[indices]).float().mean().item()\n",
    "        return acc\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 2005\n",
    "pat_counter = 0\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(X, G)\n",
    "    # print(logits)\n",
    "    loss = criterion(logits[train_idx], y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    val_acc = evaluate(model, X, G, y, val_idx)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model = model.state_dict()\n",
    "        pat_counter = 0\n",
    "    else:\n",
    "        pat_counter += 1\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        train_acc = evaluate(model, X, G, y, train_idx)\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if pat_counter >= patience:\n",
    "        print(\"Early stopping.\")\n",
    "        break\n",
    "\n",
    "# ---------------------\n",
    "# Test Evaluation\n",
    "# ---------------------\n",
    "model.load_state_dict(best_model)\n",
    "test_acc = evaluate(model, X, G, y, test_idx)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gntk-gdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
